{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<font color=teal>\n",
    "_______________________________________\n",
    "</font>\n",
    "\n",
    "\n",
    "### <font color=teal>Goal:</font>\n",
    "\n",
    "- Merge play actions and offense/defense power scores into a play by play dataset focused on play-calling\n",
    "\n",
    "### <font color=teal>Input:</font>\n",
    "\n",
    "- pbp_actions.parquet\n",
    "- defense_power.parquet\n",
    "- offense_power.parquet\n",
    "\n",
    "\n",
    "### <font color=teal>Steps:</font>\n",
    "- merge offense and defense scores into each play based on which team offense and defense\n",
    "- save the final play-calling dataset\n",
    "\n",
    "\n",
    "### <font color=teal>Code:</font>\n",
    "- /src module\n",
    "\n",
    "\n",
    "\n",
    "### <font color=teal>Output:</font>\n",
    "\n",
    "- nfl_pbp_play_calls.parquet\n",
    "\n",
    "\n",
    "\n",
    "<font color=teal>\n",
    "_______________________________________\n",
    "</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "data_directory = get_config('data_directory')\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_path = os.path.join(data_directory, \"nfl_pbp_play_calls.parquet\")\n",
    "pbp_actions_df = pd.read_parquet(full_path)\n",
    "pbp_actions_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Many of these are interesting and needed just to understand and validate the information, but they have varying effectiveness for a play call predictor\n",
    "\n",
    "- drop: season, week, play counter, -- unless we can use this to weight more recent seasons\n",
    "- not sure:\n",
    "        - drive - we get a sense of time using seconds remaining, point differential, yards_to_goal, etc.\n",
    "        - posteam - we could label this, but really offense and defense power identifies the team better for this type of application\n",
    "        - defteam - it would just take a lot longer to train - defense power is perhaps just as effective\n",
    "        - down - again, interesting from an understinf=ding of what's going on, but not really for a play call predictor\n",
    "        -\n",
    "        -\n",
    "- Keepers\n",
    "        - point differential - float\n",
    "        - yrdstogo ....float\n",
    "        - yards_to_goal - int64\n",
    "        - game seconds remaining  - float\n",
    "        - action - label\n",
    "        - yards_gained - float\n",
    "        - points gained - int\n",
    "        - defense power - float\n",
    "        - offense power - float\n",
    "        -"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keepers = [\n",
    "    'action',\n",
    "    'point_differential',\n",
    "    'ydstogo',\n",
    "    'yards_to_goal',\n",
    "    'game_seconds_remaining',\n",
    "    'defense_power',\n",
    "    'offense_power',\n",
    "    'yards_gained',\n",
    "    'points_gained'\n",
    "]\n",
    "\n",
    "df = pbp_actions_df[keepers]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert df.isna().sum().sum() == 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.select_dtypes(include='int64').shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.utils import assert_and_alert\n",
    "\n",
    "dtype_mapping = {col: 'float' for col in df.select_dtypes(include='int64')}\n",
    "df = df.astype(dtype_mapping)\n",
    "\n",
    "assert_and_alert(df.select_dtypes(include='int64').shape[1] == 0, \"expected that all integers to be converted to float\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.utils import label_encode\n",
    "\n",
    "encoded_df, labels = label_encode(df, ['action'])\n",
    "labels['action']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sns.pairplot(encoded_df[['point_differential',\n",
    "#                          'ydstogo',\n",
    "#                          'yards_to_goal',\n",
    "#                          'game_seconds_remaining',\n",
    "#                          'defense_power',\n",
    "#                          'offense_power',\n",
    "#                          'yards_gained',\n",
    "#                          'points_gained']], diag_kind='kde');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.src import regularizers\n",
    "from keras.src.optimizers import Adam, RMSprop\n",
    "\n",
    "\n",
    "def run_simple_nn(X_train, X_test, y_train, y_test):\n",
    "    # Set parameters\n",
    "    learning_rate = .01\n",
    "    activation_function = \"relu\"\n",
    "    output_function = \"linear\"\n",
    "    loss_function = \"mean_squared_error\"\n",
    "    regularization_function = regularizers.l1(0.001)\n",
    "    optimizer=RMSprop()\n",
    "\n",
    "\n",
    "    # Create a neural network model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X.shape[1], activation=activation_function))\n",
    "    model.add(Dense(64,  activation=activation_function))\n",
    "    # model.add(Dense(64, activation=activation_function, kernel_regularizer=regularization_function))\n",
    "    # model.add(Dense(15, activation=activation_function, kernel_regularizer=regularization_function))\n",
    "    model.add(Dense(1))  # Single output neuron for binary classification\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss_function,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    r = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from typing import Set\n",
    "import xgboost as xgb\n",
    "\n",
    "def run_xgboost(X_train, X_test, y_train, y_test) -> (pd.DataFrame, Set):\n",
    "    # Create an XGBoost model\n",
    "    # Convert the data into DMatrix format\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Set the parameters for XGBoost\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model = xgb.train(params, dtrain)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(dtest)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    return mse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = encoded_df[['yards_gained']].values\n",
    "X = encoded_df.drop(columns=['yards_gained', 'points_gained']).values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# mse = run_xgboost(X_train, X_test, y_train, y_test)\n",
    "run_simple_nn(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a function to create the neural network model\n",
    "def create_model(learning_rate=0.01, activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=X.shape[1], activation=activation))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Create a KerasRegressor wrapper\n",
    "model = KerasRegressor(build_fn=create_model)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.001],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Score: \", grid_result.best_score_)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create the scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize selected columns in a DataFrame\n",
    "X = scaler.fit_transform(X)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actions = [x[0] for x in list(labels['action'])]\n",
    "actions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Embedding, Dense\n",
    "# from tensorflow.keras.models import Model\n",
    "#\n",
    "#\n",
    "#\n",
    "# # Define the input layers\n",
    "# action_input = Input(shape=(1,))\n",
    "# metrics_input = Input(shape=(X.shape[1]-1,))  # Shape correction\n",
    "#\n",
    "# # Create the embedding layer for actions\n",
    "# embedding_dim = 8\n",
    "# action_embed = Embedding(input_dim=len(actions), output_dim=embedding_dim)(action_input)\n",
    "# action_flatten = tf.keras.layers.Flatten()(action_embed)\n",
    "#\n",
    "# # Combine the input layers and action embedding\n",
    "# X_concat = tf.keras.layers.Concatenate()([action_flatten, metrics_input])\n",
    "# x = Dense(32, activation='relu')(X_concat)\n",
    "# x = Dense(32, activation='relu')(x)\n",
    "#\n",
    "# # Task-specific layers for YARDS prediction\n",
    "# yards_layer = Dense(16, activation='relu')(x)\n",
    "# yards_output = Dense(1, activation='sigmoid', name='yards_output')(yards_layer)\n",
    "#\n",
    "# # Task-specific layers for POINTS prediction\n",
    "# points_layer = Dense(16, activation='relu')(x)\n",
    "# points_output = Dense(1, activation='sigmoid', name='points_output')(points_layer)\n",
    "#\n",
    "# # Define the model with multiple outputs\n",
    "# model = Model(inputs=[action_input, metrics_input], outputs=[yards_output, points_output])\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def feed_nn(X_df, y_df):\n",
    "    _actions = X_df['action'].values\n",
    "    _metrics =  X_df.drop(columns=['action']).values\n",
    "    x = X_df.values\n",
    "    X = [_actions, _metrics]\n",
    "\n",
    "    yards = y_df['yards_gained'].values\n",
    "    points = y_df['points_gained'].values\n",
    "    y = [yards, points]\n",
    "\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_complex_model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Define the input layers\n",
    "    action_input = Input(shape=(1,))\n",
    "    metrics_input = Input(shape=(X.shape[1]-1,))  # Shape correction\n",
    "\n",
    "    # Create the embedding layer for actions\n",
    "    embedding_dim = 8\n",
    "    action_embed = Embedding(input_dim=len(actions), output_dim=embedding_dim)(action_input)\n",
    "    action_flatten = tf.keras.layers.Flatten()(action_embed)\n",
    "\n",
    "    # Combine the input layers and action embedding\n",
    "    X_concat = tf.keras.layers.Concatenate()([action_flatten, metrics_input])\n",
    "    x = Dense(32, activation='relu')(X_concat)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "\n",
    "    # Task-specific layers for YARDS prediction\n",
    "    yards_layer = Dense(16, activation='relu')(x)\n",
    "    yards_output = Dense(1, name='yards_output')(yards_layer)\n",
    "\n",
    "    # Task-specific layers for POINTS prediction\n",
    "    points_layer = Dense(16, activation='relu')(x)\n",
    "    points_output = Dense(1, activation='sigmoid', name='points_output')(points_layer)\n",
    "\n",
    "    # Define the model with multiple outputs\n",
    "    model = Model(inputs=[action_input, metrics_input], outputs=[yards_output, points_output])\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'yards_output': 'mean_squared_error',\n",
    "                        'points_output': 'binary_crossentropy'},\n",
    "                  metrics={'yards_output': 'mae',\n",
    "                           'points_output': 'accuracy'})\n",
    "\n",
    "    # Define the early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    r = model.fit(x=[X_train[:, 0], X_train[:, 1:]], y=[y_train[:, 0], y_train[:, 1]],\n",
    "                  epochs=1,\n",
    "                  batch_size=64,\n",
    "                  validation_data=([X_test[:, 0], X_test[:, 1:]], [y_test[:, 0], y_test[:, 1]]),\n",
    "                  callbacks=[early_stopping])\n",
    "\n",
    "    return r"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_train, y_train = feed_nn(X_train0, y_train0)\n",
    "# X_test, y_test = feed_nn(X_test0, y_test0)\n",
    "\n",
    "# X_train = X_train0.values\n",
    "# X_test = X_test0.values\n",
    "# y_train = y_train0.values\n",
    "# y_test = y_test0.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r = run_simple_model(X_train, X_test, y_train[:,0], y_test[:,0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r.history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
