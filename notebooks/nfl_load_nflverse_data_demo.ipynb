{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=#0e0654>NFL ingest and load process</font>\n",
    "Chris Lomeli\n",
    "Springboard Capstone"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=#0e0654>This notebook is for demonstration of the NFL ingest and load process</font>\n",
    "\n",
    "The goal for this notebook is to demonstrate the workflow of (1) downloading NFL data from [NFLVerse](https://github.com/nflverse), (2) wrangling and splitting dimensional data into a relational database and (3) transforming the data a subset of the data into a team/week win/loss prediction model.\n",
    "\n",
    "The steps to accomplish this are:\n",
    "\n",
    "- download data from NFLVerse\n",
    "\n",
    "- clean and restructure the data into semi-normailzed relational tables\n",
    "- prepare the data by querying a subset of the data for a team/week level input dataset that can be used to predict win/loss\n",
    "- perform feature selection to get the right features tthen aggregate the weigted averages into power scores\n",
    "- merge game and power score data into the input dataset for our experiment\n",
    "\n",
    "This job would normally be run from nfl_main_job.py, which autonomously executes the individual steps in the same way you see in this notebook.\n",
    "\n",
    "\n",
    "<img src=\"../images/nfl.png\" alt=\"NFLVerse Ingest\">\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 1px solid rgba(147, 112, 219, 0.1); margin: 1px 0;\"></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">imports</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from src import configs\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:16:20.288002Z",
     "start_time": "2023-07-20T22:16:19.906355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:16:20.929417Z",
     "start_time": "2023-07-20T22:16:20.288730Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.nfl_00_load_nflverse_data import read_nflverse_datasets\n",
    "from src.nfl_01_load_nfl_database import create_nfl_database\n",
    "from src.nfl_02_prepare_weekly_stats import prepare_team_week_dataset\n",
    "from src.nfl_03_perform_feature_selection import perform_team_week_feature_selection\n",
    "from src.nfl_04_merge_game_feature_selection import merge_team_week_features"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">housekeeping</h3>\n",
    "</div>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Get the logger\n",
    "logger = configs.configure_logging(\"pbp_logger\")\n",
    "logger.setLevel(logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:16:20.931557Z",
     "start_time": "2023-07-20T22:16:20.929647Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">download nflverse data</h3>\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "our goal in this step is to get the information downloaded with as few risk as possible\n",
    "\n",
    "this protects us from any unexpected changes in the nflverse datasets or issues wihtout own transformations\n",
    "\n",
    "once we have the data safely in our system we can dimension and store the data in a database with as many validations and retries as necessary\n",
    "\n",
    "normally we will run this from a python job 'src.nfl_main_job.py' but for demo purposes we'll run these here\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#0e0654\">read nflverse data to output folders</font>\n",
    "\n",
    "<font color=#0e0654>\n",
    "\n",
    "- our goal is to get the data stored without risk of failures - we store directly to local or s3\n",
    "- The files we want are configures in the configs.py code\n",
    "- using a synchronous http client\n",
    "- and a fixed size executor thread pool\n",
    "<font/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:16:20,931 - INFO - begin downloads ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:16:28,754 - INFO - downloads complete ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    }
   ],
   "source": [
    "read_nflverse_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:16:28.758751Z",
     "start_time": "2023-07-20T22:16:20.932262Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 1px solid rgba(147, 112, 219, 0.4); margin: 1px 0;\"></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#0e0654\">load to database</font>\n",
    "\n",
    "<font color=#0e0654>\n",
    "\n",
    "In this step we read from the output directory\n",
    "\n",
    "we then split the data into several dimensions based on cardinality\n",
    "\n",
    "<br>\n",
    "\n",
    "for example,\n",
    "\n",
    "<br>\n",
    "\n",
    "* explode the player participation array columns into thier own datasets, and\n",
    "* create a play_actions dataset that contains key play by play info\n",
    "* pull out all the player events in the play-by-play data, cross-reference them to the team they are playing for in that week\n",
    "* pull out game data e.g. game date, final scores, home and away teams, et.\n",
    "\n",
    "<br>\n",
    "\n",
    "we load all dimensions to an relational database for availability to other experiments\n",
    "\n",
    "\n",
    "todo:  the load process should be using a bulk/copy instead of inserts\n",
    "<font/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:16:28,759 - INFO - Reading all files from pbp\n",
      "2023-07-20 15:16:32,896 - INFO - Impute columns to 0\n",
      "2023-07-20 15:16:33,092 - INFO - impute non binary pbp columns ...\n",
      "2023-07-20 15:16:33,866 - INFO - Impute columns to 0\n",
      "2023-07-20 15:16:34,489 - INFO - Impute columns to 0:00\n",
      "2023-07-20 15:16:35,875 - INFO - Impute columns to NA\n",
      "2023-07-20 15:16:41,408 - INFO - moving play_id to play_counter, and creating a joinable play_id key\n",
      "2023-07-20 15:16:42,259 - INFO - Conform key actions like pass, rush, kickoff, etc.... \n",
      "2023-07-20 15:16:54,577 - INFO - Validate actions dimension ...\n",
      "2023-07-20 15:16:54,858 - INFO - checking play_action counts...\n",
      "2023-07-20 15:16:54,870 - INFO - Creating new drive dimension...\n",
      "2023-07-20 15:16:54,941 - INFO - Validate drive_df dimension ...\n",
      "2023-07-20 15:16:55,168 - INFO - Creating new situations dimension...\n",
      "2023-07-20 15:16:55,235 - INFO - Validate situation_df dimension ...\n",
      "2023-07-20 15:16:55,446 - INFO - Creating new metrics dimension...\n",
      "2023-07-20 15:16:55,493 - INFO - Validate play_metrics_df dimension ...\n",
      "2023-07-20 15:16:55,583 - INFO - Creating new game dimension...\n",
      "2023-07-20 15:16:56,285 - INFO - Validate games dimension ...\n",
      "2023-07-20 15:16:56,288 - INFO - Create stats for pbp player involvement by play ...\n",
      "2023-07-20 15:17:02,439 - INFO - Creating new analytics dimension...\n",
      "2023-07-20 15:17:02,779 - INFO - Reading all files from pbp-participation\n",
      "2023-07-20 15:17:03,120 - INFO - pbp_participation:  create a joinable play_id column ...\n",
      "2023-07-20 15:17:03,386 - INFO - Calculating defense and offense team names by player and play...\n",
      "2023-07-20 15:17:06,078 - INFO - Exploding offensive players to their own dataset...\n",
      "2023-07-20 15:17:07,648 - INFO - Exploding defense_players to their own dataset...\n",
      "2023-07-20 15:17:15,941 - WARNING - count after merge: 6903461 != 6902991\n",
      "2023-07-20 15:17:20,132 - INFO - Reading all files from injuries\n",
      "2023-07-20 15:17:20,168 - INFO - Prep injury data...\n",
      "2023-07-20 15:17:20,169 - INFO - Conforming names (e.g. gsis_id -> player_id)\n",
      "2023-07-20 15:17:20,179 - INFO - Merge sparse injury columns\n",
      "2023-07-20 15:17:20,181 - INFO - Get best values for null report_statuses...\n",
      "2023-07-20 15:17:20,240 - INFO - check that all positions are correct...\n",
      "2023-07-20 15:17:20,247 - INFO - Reading all files from player-stats\n",
      "2023-07-20 15:17:20,292 - INFO - fix specific player_stats: <function player_stats_fixes at 0x14970ed30>..\n",
      "2023-07-20 15:17:20,367 - INFO - replace empty position_groups with position info...\n",
      "2023-07-20 15:17:20,381 - INFO - replace empty player_name with player_display_name info...\n",
      "2023-07-20 15:17:20,394 - INFO - replace empty headshot_url with 'none'...\n",
      "2023-07-20 15:17:20,405 - INFO - fillna(0) for all binary columns...\n",
      "2023-07-20 15:17:20,405 - INFO - Impute columns to 0\n",
      "2023-07-20 15:17:20,589 - WARNING - After merge player_stats count changed - went from 124081 to 124083\n",
      "2023-07-20 15:17:20,594 - INFO - Reading all files from players\n",
      "2023-07-20 15:17:20,620 - INFO - Process players dataset...\n",
      "2023-07-20 15:17:20,621 - INFO - drop players without gsis_ids - they won't link to player_stats\n",
      "2023-07-20 15:17:20,636 - INFO - fill empty players status to 'NONE'\n",
      "2023-07-20 15:17:20,644 - INFO - rename gsis_id to player_id...\n",
      "2023-07-20 15:17:20,647 - INFO - Reading all files from advstats-season-def\n",
      "2023-07-20 15:17:20,652 - INFO - Reading all files from advstats-season-pass\n",
      "2023-07-20 15:17:20,655 - INFO - Reading all files from advstats-season-rec\n",
      "2023-07-20 15:17:20,658 - INFO - Reading all files from advstats-season-rush\n",
      "2023-07-20 15:17:20,661 - INFO - Reading all files from nextgen-passing\n",
      "2023-07-20 15:17:20,691 - INFO - Reading all files from nextgen-receiving\n",
      "2023-07-20 15:17:20,729 - INFO - Reading all files from nextgen-rushing\n",
      "2023-07-20 15:17:20,750 - INFO - create table play_actions in schema controls\n",
      "2023-07-20 15:17:59,990 - INFO - create table game_drive in schema controls\n",
      "2023-07-20 15:18:19,973 - INFO - create table play_analytics in schema controls\n",
      "2023-07-20 15:19:31,962 - INFO - create table play_situations in schema controls\n",
      "2023-07-20 15:19:58,132 - INFO - create table play_metrics in schema controls\n",
      "2023-07-20 15:20:20,504 - INFO - create table player_events in schema controls\n",
      "2023-07-20 15:20:30,102 - INFO - create table game_info in schema controls\n",
      "2023-07-20 15:20:30,242 - INFO - create table player_participation in schema controls\n",
      "2023-07-20 15:24:45,265 - INFO - create table injuries in schema controls\n",
      "2023-07-20 15:24:47,250 - INFO - create table players in schema controls\n",
      "2023-07-20 15:24:48,811 - INFO - create table player_stats in schema controls\n",
      "2023-07-20 15:25:09,279 - INFO - create table adv_stats_def in schema controls\n",
      "2023-07-20 15:25:09,681 - INFO - create table adv_stats_pass in schema controls\n",
      "2023-07-20 15:25:09,738 - INFO - create table adv_stats_rec in schema controls\n",
      "2023-07-20 15:25:09,956 - INFO - create table adv_stats_rush in schema controls\n",
      "2023-07-20 15:25:10,079 - INFO - create table nextgen_pass in schema controls\n",
      "2023-07-20 15:25:10,454 - INFO - create table nextgen_rec in schema controls\n",
      "2023-07-20 15:25:11,223 - INFO - create table nextgen_rush in schema controls\n"
     ]
    }
   ],
   "source": [
    "create_nfl_database()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:25:12.000768Z",
     "start_time": "2023-07-20T22:16:28.760081Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 1px solid rgba(147, 112, 219, 0.4); margin: 1px 0;\"></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"background-color: teal; padding: 10px;\">\n",
    "    <h3 style=\"color: white;\">prepare data for team/week win/loss experiment</h3>\n",
    "</div>\n",
    "\n",
    "Our goal is to use the nfl dimensions we have created to prepare data for our a team/week experiment\n",
    "\n",
    "The team_week experiment aims to select the best features in the nflverse data to predict win/loss\n",
    "\n",
    "The expectations is not that we can really predict win/loss any better than current statistical approaches, but to experiment with potentials for ML\n",
    "\n",
    "Normally we will run this from a python job 'src.nfl_main_job.py' but for demo purposes we'll run these here\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#0e0654\">query and build a team/week dataset</font>\n",
    "\n",
    "<font color=#0e0654>\n",
    "\n",
    "In this step we use SQL queries to pull play actions, events and statistics from the nfl database\n",
    "\n",
    "We are lagging and leading to fill incomplete data in the original dataset\n",
    "\n",
    "We are merging all statistics into defense and offense datasets so they can be attributed to specific teams\n",
    "\n",
    "for example, for the Ravens (BAL) vs Jets (NYJ) in week 1 of 2022 we want separate sets for BAL and NYJ - so each team has its own stats\n",
    "\n",
    "We are aggregating up to the Season, Week, Team level for this application\n",
    "\n",
    "We can concatenate available statistics, which are also at the Season, Week, Team level\n",
    "\n",
    "finally, we create play_action, offense and defense datasets in our data directory and optionally back to the database\n",
    "\n",
    "<font/>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:25:12,001 - INFO - Build a 'control' dataset with all seasons and weeks...\n",
      "2023-07-20 15:25:12,601 - INFO - query and modify play actions data ...\n",
      "2023-07-20 15:25:16,297 - INFO - double checking play actions before save...\n",
      "2023-07-20 15:25:16,319 - INFO - query and modify game info data ...\n",
      "2023-07-20 15:25:16,356 - INFO - query and modify next gen passing data ...\n",
      "2023-07-20 15:25:16,398 - INFO - query and modify next gen rushing data ...\n",
      "2023-07-20 15:25:16,421 - INFO - query and modify play-by-play player events ...\n",
      "2023-07-20 15:25:21,086 - INFO - query defense player_stats data ...\n",
      "2023-07-20 15:25:21,192 - INFO - query offense player_stats data ...\n",
      "2023-07-20 15:25:21,365 - INFO - back and forward fill ngs_air_power metrics by week ...\n",
      "2023-07-20 15:25:21,382 - INFO - back and forward fill ngs_ground_power metrics by week ...\n",
      "2023-07-20 15:25:21,392 - INFO - back and forward fill pbp_events metrics by week ...\n",
      "2023-07-20 15:25:21,400 - INFO - back and forward fill defense_stats metrics by week ...\n",
      "2023-07-20 15:25:21,414 - INFO - back and forward fill possession_stats metrics by week ...\n",
      "2023-07-20 15:25:21,437 - INFO - back and forward fill ngs_air_power metrics by week ...\n",
      "2023-07-20 15:25:21,453 - INFO - merge offense events info into a single offense stats dataset...\n",
      "2023-07-20 15:25:21,457 - INFO - possession_stats before: (3961, 28), after: (3961, 54)\n",
      "2023-07-20 15:25:21,461 - INFO - offense_shape before: (3961, 28), after : (3812, 62)\n",
      "2023-07-20 15:25:21,464 - INFO - merge defense events info into a single defense stats dataset...\n",
      "2023-07-20 15:25:21,466 - INFO - defense shape before: (3961, 13), after: (3961, 19)\n",
      "2023-07-20 15:25:21,470 - INFO - defense_stats before: (3961, 13), after game_info: (3812, 27) \n",
      "2023-07-20 15:25:21,473 - INFO - save play action and merged offense and defense stats ...\n",
      "2023-07-20 15:25:21,474 - INFO - writing file tmp_weekly_offense\n",
      "2023-07-20 15:25:21,604 - INFO - writing file tmp_weekly_defense\n",
      "2023-07-20 15:25:21,616 - INFO - writing file tmp_weekly_play_actions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "prepare_team_week_dataset(store_to_db=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:25:22.236159Z",
     "start_time": "2023-07-20T22:25:12.002737Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 1px solid rgba(147, 112, 219, 0.4); margin: 1px 0;\"></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#0e0654\">feature selection</font>\n",
    "\n",
    "<font color=#0e0654>\n",
    "\n",
    "In this step we use the weekly datasets we've created to find the best feature to predict game win/loss\n",
    "\n",
    "We perform some data prep, including scaling, categorical encoding\n",
    "\n",
    "We perform sklearn correlations, generally and specifically for the target win/loss column\n",
    "\n",
    "After some automl experiments, we use xgboost to determine the best features for predicting win/loss\n",
    "\n",
    "We separate the top features for defense and offense and calculate a weighted average of all to get a single defense_power and offense_power score\n",
    "\n",
    "We perform a sanity check to validate that the power score columns learn as well as the individual stats, and has the ability to learn\n",
    "\n",
    "<font/>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:25:22,235 - INFO - SelectNFLFeatures\n",
      "2023-07-20 15:25:22,236 - INFO - load tmp_weekly_offense\n",
      "2023-07-20 15:25:22,244 - INFO - prepare a features dataset\n",
      "2023-07-20 15:25:22,244 - INFO - encode the target win/loss column\n",
      "2023-07-20 15:25:22,245 - INFO - create a features dataframe for feature selection ...\n",
      "2023-07-20 15:25:22,246 - INFO - scale all features  ...\n",
      "2023-07-20 15:25:23,174 - INFO - get percentage contribution of offensive and defensive features\n",
      "2023-07-20 15:25:23,177 - INFO - calculate weighted average of offensive and defensive features\n",
      "2023-07-20 15:25:23,184 - INFO - Writing to tmp_offense_week_features\n",
      "2023-07-20 15:25:23,206 - INFO - SelectNFLFeatures\n",
      "2023-07-20 15:25:23,207 - INFO - load tmp_weekly_defense\n",
      "2023-07-20 15:25:23,211 - INFO - prepare a features dataset\n",
      "2023-07-20 15:25:23,211 - INFO - encode the target win/loss column\n",
      "2023-07-20 15:25:23,212 - INFO - create a features dataframe for feature selection ...\n",
      "2023-07-20 15:25:23,213 - INFO - scale all features  ...\n",
      "2023-07-20 15:25:23,996 - INFO - get percentage contribution of offensive and defensive features\n",
      "2023-07-20 15:25:23,998 - INFO - calculate weighted average of offensive and defensive features\n",
      "2023-07-20 15:25:24,004 - INFO - Writing to tmp_defense_week_features\n"
     ]
    }
   ],
   "source": [
    "perform_team_week_feature_selection()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:25:24.019044Z",
     "start_time": "2023-07-20T22:25:22.237414Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 1px solid rgba(147, 112, 219, 0.4); margin: 1px 0;\"></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#0e0654\">merge play action and performance features into play action</font>\n",
    "\n",
    "<font color=#0e0654>\n",
    "\n",
    "In this step we merge defense and offense data back into play_action data\n",
    "\n",
    "<br>\n",
    "\n",
    "For example:\n",
    "\n",
    "\n",
    "Taking the Ravens (BAL) vs Jets (NYJ) game in in week 1 of 2022\n",
    "\n",
    "for each drive the offense and defense changes:  BAL is offense in drive 1, then defense in drive 2\n",
    "\n",
    "we create two different slices for that single game - one focused on BAL and the other on NYJ\n",
    "\n",
    "we then fold in the offense and defense stats for each drive from our defense and offense datasets\n",
    "\n",
    "<br>\n",
    "\n",
    "* for drive 1 where BAL is playing offense:\n",
    "\n",
    "    - the offense's offense_power (offense_op) will come from BAL's offense stats\n",
    "    - the offense's defense_power (offense_dp) will come from BAL's defense stats\n",
    "    - the defense's offense_power (defense_op) will come from NYJ's offense stats\n",
    "    - the defense's defense_power (defense_dp) will come from NYJ's defense stats\n",
    "\n",
    "\n",
    "<font/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:25:24,018 - INFO - loading weekly features into a single game dataset...\n",
      "2023-07-20 15:25:24,019 - INFO - Reading from tmp_weekly_play_actions\n",
      "2023-07-20 15:25:24,145 - INFO - Reading from tmp_offense_week_features\n",
      "2023-07-20 15:25:24,149 - INFO - Reading from tmp_defense_week_features\n",
      "2023-07-20 15:25:24,152 - INFO - merge stats into play_actions...\n",
      "2023-07-20 15:25:25,020 - INFO - merging offense_OP...\n",
      "2023-07-20 15:25:26,048 - INFO - merging offense_DP...\n",
      "2023-07-20 15:25:27,169 - INFO - merging defense_OP...\n",
      "2023-07-20 15:25:27,884 - INFO - merging defense_DP...\n",
      "2023-07-20 15:25:27,910 - INFO - aggregate game dataset weekly stats by season, week, team...\n",
      "2023-07-20 15:25:28,172 - INFO - writing file weekly_game_stats\n"
     ]
    }
   ],
   "source": [
    "merge_team_week_features()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:25:28.195642Z",
     "start_time": "2023-07-20T22:25:24.019379Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div style=\"border: 1px solid rgba(147, 112, 219, 0.4); margin: 1px 0;\"></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-20T22:25:28.199545Z",
     "start_time": "2023-07-20T22:25:28.195980Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
