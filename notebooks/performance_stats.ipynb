{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"custom.css\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>imports</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../src\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T18:47:50.488629Z",
     "start_time": "2023-07-06T18:47:50.486689Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from src import *\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T18:47:50.951165Z",
     "start_time": "2023-07-06T18:47:50.489145Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>housekeeping</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "db = database_loader.DatabaseLoader(get_config('connection_string'))\n",
    "DEBUG=True\n",
    "COMMIT_TO_DATABASE=True\n",
    "SCHEMA='controls'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T18:47:50.954007Z",
     "start_time": "2023-07-06T18:47:50.951554Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>game info data</font>\n",
    "Aggregated up from the play-by-play dataset.\n",
    "\n",
    "We want each team to have its own record for each season and week.\n",
    "\n",
    "So for any given game there will be two records, one for the home team having its stats, and another for the away team - having the opposite stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We want each team to have a record for each season and week.\n",
    "\n",
    "game_df = db.query_to_df(\"\"\"\n",
    "   --home team labels\n",
    "    select season,\n",
    "           week,\n",
    "           home_team                 as team,\n",
    "           home_score                as team_score,\n",
    "           home_coach                as team_coach,\n",
    "           away_team                 as opposing_team,\n",
    "           away_score                as opposing_score,\n",
    "           away_coach                as opposing_coach,\n",
    "           (home_score - away_score) as spread,\n",
    "           count(*)\n",
    "\n",
    "    from controls.game_info G\n",
    "    group by season, week, home_team, home_score, away_score, away_team, home_coach, away_coach\n",
    "    UNION ALL\n",
    "    --away team labels\n",
    "    select season,\n",
    "           week,\n",
    "           away_team                 as team,\n",
    "           away_score                as team_score,\n",
    "           away_coach                as team_coach,\n",
    "           home_team                 as opposing_team,\n",
    "           home_score                as opposing_score,\n",
    "           home_coach                as opposing_coach,\n",
    "           (away_score - home_score) as spread,\n",
    "           count(*)\n",
    "\n",
    "    from controls.game_info G\n",
    "    group by season, week, home_team, home_score, away_score, away_team, home_coach, away_coach\n",
    "\"\"\")\n",
    "\n",
    "game_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">A single game should have two 'opposite' records</font>\n",
    "let's check that out for the 2017 match between DEN and NYG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "game_df.loc[(game_df.season==2017) & (game_df.week==6) & (game_df.team.isin(['DEN', 'NYG']))]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">There should be no team with two records for any give week</font>\n",
    "let's validate that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fail if there are any group counts > 1\n",
    "double_counts = game_df.loc[(game_df['count'].astype(int) > 1)].shape[0]\n",
    "assert double_counts == 0"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>next gen stats passing<font/>\n",
    "group by <font color=red>season, week, team</font> ( and top-passing-player_position )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "ngs_air_power = db.query_to_df(\"\"\"\n",
    "    with base as (\n",
    "    select season, week, team_abbr as team,\n",
    "           pass_touchdowns,\n",
    "           avg_time_to_throw,\n",
    "           avg_completed_air_yards,\n",
    "           avg_intended_air_yards,\n",
    "           avg_air_yards_differential,\n",
    "           aggressiveness,\n",
    "           max_completed_air_distance,\n",
    "           avg_air_yards_to_sticks,\n",
    "           attempts,\n",
    "           pass_yards,\n",
    "           interceptions,\n",
    "           passer_rating,\n",
    "           completions,\n",
    "           completion_percentage,\n",
    "           expected_completion_percentage,\n",
    "           completion_percentage_above_expectation,\n",
    "           avg_air_distance,\n",
    "           max_air_distance,\n",
    "        row_number() over (partition by season, week, team_abbr, player_position order by pass_yards desc) as rn\n",
    "    from controls.nextgen_pass\n",
    "--    where season=2016 and week=1 and team_abbr = 'CHI'\n",
    "    order by team_abbr, player_position, season desc, week )\n",
    "    select * from base where rn = 1 and week > 0\n",
    "\"\"\")\n",
    "\n",
    "ngs_air_power.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=teal>next gen stats rushing<font/>\n",
    "group by <font color=red>season, week, team</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "ngs_ground_power = db.query_to_df(\"\"\"\n",
    "with base as (\n",
    "    select season, week, team_abbr as team, rush_yards,\n",
    "           efficiency,\n",
    "           percent_attempts_gte_eight_defenders,\n",
    "           avg_time_to_los,\n",
    "           rush_attempts,\n",
    "           expected_rush_yards,\n",
    "           rush_yards_over_expected,\n",
    "           avg_rush_yards,\n",
    "           rush_yards_over_expected_per_att,\n",
    "           rush_pct_over_expected,\n",
    "           rush_touchdowns,\n",
    "           player_gsis_id,\n",
    "           player_first_name,\n",
    "           player_last_name,\n",
    "           player_jersey_number,\n",
    "           player_short_name,\n",
    "           row_number() over (partition by season, week, team_abbr order by rush_yards desc) as rn\n",
    "    from controls.nextgen_rush\n",
    "    order by  team_abbr, season desc, week)\n",
    "select * from base where week > 0\n",
    "\"\"\" )\n",
    "\n",
    "ngs_ground_power.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>play-by-play events<font/>\n",
    "players are called out for certain events like fumbles, touchdowns, etc. in play-by-play\n",
    "we already picked these out during the transform step,\n",
    "  and expanded so that each team has its own records irrespective of the opposing team played.\n",
    "Now we pivot and sum all events by  <font color=red>season, week, team</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "pbp_events = db.query_to_df(\"\"\"\n",
    "SELECT\n",
    "    season, week, team,\n",
    "    SUM(CASE WHEN event = 'fumble' THEN 1 else 0 END) AS fumble,\n",
    "    SUM(CASE WHEN event = 'own_kickoff_recovery' THEN 1 else 0 END) AS own_kickoff_recovery,\n",
    "    SUM(CASE WHEN event = 'safety' THEN 1 else 0 END) AS safety,\n",
    "    SUM(CASE WHEN event = 'tackle' THEN 1 else 0 END) AS tackle,\n",
    "    SUM(CASE WHEN event = 'qb_hit' THEN 1 else 0  END) AS qb_hit,\n",
    "    SUM(CASE WHEN event = 'touchdown' THEN 1  else 0 END) AS touchdown,\n",
    "    SUM(CASE WHEN event = 'interception' THEN 1 else 0 END) AS interception,\n",
    "    SUM(CASE WHEN event = 'sack' THEN 1 else 0 END) AS sack\n",
    "FROM controls.player_events where week > 0\n",
    "group by season, week, team\n",
    "order by season desc, team, week\n",
    "\"\"\")\n",
    "\n",
    "pbp_events.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>player stats<font/>\n",
    "Each player's stats by are collected by game and play\n",
    "For this dimension reduction exercise we roll up to <font color=red>season, week, team</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "player_stats = db.query_to_df(\"\"\"\n",
    "select\n",
    "    season,\n",
    "    week,\n",
    "    team,\n",
    "    sum(completions) as ps_completions,\n",
    "    sum(attempts) as ps_attempts,\n",
    "    sum(passing_yards) as passing_yards,\n",
    "    sum(passing_tds) as passing_tds,\n",
    "    sum(interceptions) as ps_interceptions,\n",
    "    sum(sacks) as sacks,\n",
    "    sum(sack_yards) as sack_yards,\n",
    "    sum(sack_fumbles) as sack_fumbles,\n",
    "    sum(sack_fumbles_lost) as sack_fumbles_lost,\n",
    "    sum(passing_air_yards) as passing_air_yards,\n",
    "    sum(passing_yards_after_catch) as passing_yards_after_catch,\n",
    "    sum(passing_first_downs) as passing_first_downs,\n",
    "    avg(passing_epa) as passing_epa,\n",
    "    sum(passing_2pt_conversions) as passing_2pt_conversions,\n",
    "    avg(pacr) as avg_pacr,\n",
    "    avg(dakota) as avg_dakota,\n",
    "    sum(carries) as carries,\n",
    "    sum(rushing_yards) as rushing_yards,\n",
    "    sum(rushing_tds) as rushing_tds,\n",
    "    sum(rushing_fumbles) as rushing_fumbles,\n",
    "    sum(rushing_fumbles_lost) as rushing_fumbles_lost,\n",
    "    sum(rushing_first_downs) as rushing_first_downs,\n",
    "    avg(rushing_epa) as avg_rushing_epa,\n",
    "    sum(rushing_2pt_conversions) as rushing_2pt_conversions,\n",
    "    sum(receptions) as receptions,\n",
    "    sum(targets) as targets,\n",
    "    sum(receiving_yards) as receiving_yards,\n",
    "    sum(receiving_tds) as receiving_tds,\n",
    "    sum(receiving_fumbles) as receiving_fumbles,\n",
    "    sum(receiving_fumbles_lost) as receiving_fumbles_lost,\n",
    "    sum(receiving_air_yards) as receiving_air_yards,\n",
    "    sum(receiving_yards_after_catch) as receiving_yards_after_catch,\n",
    "    sum(receiving_first_downs) as receiving_first_downs,\n",
    "    avg(receiving_epa) as avg_receiving_epa,\n",
    "    sum(receiving_2pt_conversions) as receiving_2pt_conversions,\n",
    "    sum(racr) as racr,\n",
    "    sum(target_share) as target_share,\n",
    "    sum(air_yards_share) as air_yards_share,\n",
    "    sum(wopr) as wopr,\n",
    "    sum(special_teams_tds) as special_teams_tds\n",
    "from controls.player_stats\n",
    "group by season,\n",
    "week,\n",
    "team\n",
    "order by season desc, team,  week\n",
    "\"\"\")\n",
    "\n",
    "player_stats.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>play by play analytics</font>\n",
    "Analytics are part of the play-by-play dataset - they are collected for each play in each game.\n",
    "\n",
    "For this dimensionality reduction step we roll them up to the player stats level.\n",
    "\n",
    "The stats we get are for each play, and those probabilities\n",
    "  and play level incrementals like WPA and EPA don't make sense in a rollup like this (I think)\n",
    "  so for this rollup we'll use just EP and WP and well take the first and last metric form each season, week, team groping\n",
    "\n",
    "We'll also separate home and away teams into their own set, so that for each game there will be two separate sets of analytics, one for the home team and one fr the away team."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">helper functions</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List, NamedTuple\n",
    "\n",
    "class Col(NamedTuple):\n",
    "    name: str\n",
    "    alias: str\n",
    "\n",
    "def build_pivot_sql(team_col: str,  pivot_cols: List[Col], additional_cols: List[Col]):\n",
    "    db_table = 'controls.play_analytics'\n",
    "\n",
    "    base_cols = ['season',\n",
    "                 'week']\n",
    "    metrics = []\n",
    "    for col in pivot_cols:\n",
    "        metrics.append(\n",
    "            f\"\"\"\n",
    "            MAX(CASE WHEN RN = 1 THEN {col.alias} END) AS start_{col.alias},\n",
    "            MAX(CASE WHEN RN = (total_rows/2) THEN {col.alias} END) AS half_{col.alias}\"\"\")\n",
    "\n",
    "    inner_cols = base_cols +  [f\"{team_col} as team \"] + [f\"{p.name} as {p.alias}\" for p in pivot_cols] + [f\"{p.name} as {p.alias}\" for p in additional_cols]\n",
    "    inner_select = \",\".join(inner_cols)\n",
    "\n",
    "    outer_cols = base_cols + [\"team\"] +  [f\"{p.alias}\" for p in additional_cols] + metrics\n",
    "    outer_select = \",\".join(outer_cols)\n",
    "    outer_group = \",\".join(base_cols + [\"team\"] +  [f\"{p.alias}\" for p in additional_cols])\n",
    "\n",
    "    station_cols = base_cols + [team_col]\n",
    "    stations = \",\".join(station_cols)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    WITH ranked_rows AS (\n",
    "        SELECT {inner_select},\n",
    "             ROW_NUMBER() OVER (PARTITION BY\n",
    "                {stations} ORDER BY play_counter) AS RN,\n",
    "             COUNT(*) OVER (PARTITION BY\n",
    "                {stations}) AS total_rows\n",
    "        FROM {db_table}\n",
    "    )\n",
    "    SELECT\n",
    "        {outer_select}\n",
    "    FROM ranked_rows\n",
    "    GROUP BY {outer_group}\n",
    "    order by season desc, team, week\n",
    "    \"\"\"\n",
    "\n",
    "    if DEBUG:\n",
    "        print(sql)\n",
    "    return sql\n",
    "\n",
    "def build_pivot(team_col: str,  pivot_cols: List[Col],  additional_cols: List[Col]):\n",
    "    sql = build_pivot_sql(team_col, pivot_cols, additional_cols)\n",
    "    df = db.query_to_df( sql )\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">home team statistics</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "pivot_cols = [\n",
    "    Col('home_wp', \"team_wp\"),\n",
    "    Col('away_wp', \"opponent_wp\"),\n",
    "]\n",
    "\n",
    "home_analytics_df = build_pivot(team_col=\"home_team\", pivot_cols=pivot_cols, additional_cols=[Col(\"away_team\", \"opponent\")])\n",
    "home_analytics_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">away team statistics</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "pivot_cols = [\n",
    "    Col('away_wp', \"team_wp\"),\n",
    "    Col('home_wp', \"opponent_wp\")\n",
    "]\n",
    "\n",
    "away_analytics_df = build_pivot(team_col=\"away_team\", pivot_cols=pivot_cols, additional_cols=[Col(\"home_team\", \"opponent\")])\n",
    "away_analytics_df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">home and away team statistics appended together</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "team_analytics = pd.concat([home_analytics_df, away_analytics_df])\n",
    "team_analytics.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>validate that all of these datasets will merge 'horizontally'</font>\n",
    "We want one record for each season, week and team.\n",
    "\n",
    "The metrics themselves pivot horizontally as columns - all the metrics we created above become columns in this final dataset\n",
    "so we expect that with each merge the number of columns grows, but the row count stays the same\n",
    "\n",
    "Since we are using this dataset for dimensionality reduction it's ok if we loose a few rows on the join.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">helper functions</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def calc_coverage(title: str, df: DataFrame):\n",
    "    first = df.season.min()\n",
    "    last = df.season.max()\n",
    "    first_wk = df.week.min()\n",
    "    last_wk = df.week.max()\n",
    "    seasons = df.season.nunique()\n",
    "    print(f\"Shape of {title:30}:  {df.shape},\\t Contains {seasons} seasons, starting with {first} and ending in {last} min week: {first_wk}, max week : {last_wk}\")\n",
    "\n",
    "def print_columns(title, df):\n",
    "    print(f\"\\n---------\\n{title.strip()} colums\")\n",
    "    for col in df.columns:\n",
    "        print(col)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">get shapes before merge</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calc_coverage(\"Team analytics \", team_analytics)\n",
    "calc_coverage(\"ngs_air_power  \", ngs_air_power)\n",
    "calc_coverage(\"ngs_ground_power \", ngs_ground_power)\n",
    "calc_coverage(\"pbp_events  \", pbp_events)\n",
    "calc_coverage(\"player_stats  \", player_stats)\n",
    "calc_coverage(\"game info  \", game_df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ngs_air_power.drop(columns=['rn'], inplace=True)\n",
    "ngs_ground_power.drop(columns=['rn'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    print_columns(\"Team analytics \", team_analytics)\n",
    "    print_columns(\"ngs_air_power  \", ngs_air_power)\n",
    "    print_columns(\"ngs_ground_power \", ngs_ground_power)\n",
    "    print_columns(\"pbp_events  \", pbp_events)\n",
    "    print_columns(\"player_stats  \", player_stats)\n",
    "    print_columns(\"game Info     \", game_df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">get shapes after each  merge</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged = pd.merge(ngs_ground_power, ngs_air_power, on=['season', 'week', 'team'])\n",
    "print(\"shape after merging ngs_ground_power + ngs_air_power \", merged.shape)\n",
    "merged = pd.merge(merged, pbp_events, on=['season', 'week', 'team'])\n",
    "print(\"shape after merging merged + pbp_events              \", merged.shape)\n",
    "merged = pd.merge(merged, player_stats, on=['season', 'week', 'team'])\n",
    "print(\"shape after merging merged + player_stats            \", merged.shape)\n",
    "merged = pd.merge(merged, team_analytics, on=['season', 'week', 'team'])\n",
    "print(\"shape after merging merged + team_analytics          \", merged.shape)\n",
    "merged = pd.merge(merged, game_df, on=['season', 'week', 'team'])\n",
    "print(\"shape after merging merged + game_df                 \", merged.shape)\n",
    "\n",
    "merged.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">verify that there are no team weeks with more than one record</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "overlaps = 0\n",
    "for col in merged.columns:\n",
    "    if str(col).endswith(\"_y\") or str(col).endswith(\"_x\") or str(col) == \"rn\":\n",
    "        print(col)\n",
    "        overlaps += 1\n",
    "\n",
    "assert overlaps == 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=teal>review and impute our new dataset</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">review our dataset</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "team_week_stats = merged\n",
    "total_rows = team_week_stats.shape[0]\n",
    "team_week_stats.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "team_week_stats.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">impute missing values</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "missing_values = team_week_stats.isnull().sum().sort_values(ascending=False)\n",
    "percentage_missing = (missing_values / total_rows) * 100\n",
    "percentage_missing = percentage_missing.reset_index()\n",
    "percentage_missing.columns = ['column', 'percentage_missing']\n",
    "percentage_missing.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove analytics columns that are null -- we can't zero them because that changes the overall scoring - they are all expeceted values anyway so should not really be included\n",
    "# team_week_stats.drop(columns=['expected_rush_yards',  ])\n",
    "cols = percentage_missing.loc[(percentage_missing.percentage_missing > 0), 'column'].to_numpy()\n",
    "team_week_stats.drop(columns=cols, inplace=True)\n",
    "team_week_stats.isnull().sum().sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">interactively review distributions and decide which columns to keep</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def hist_charts(numeric_columns):\n",
    "    # Calculate the number of rows and columns for the grid\n",
    "    num_cols = 4\n",
    "    num_rows = (len(numeric_columns.columns) + num_cols - 1) // num_cols\n",
    "\n",
    "    # Generate separate histograms using seaborn for each numeric column\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3*num_rows))\n",
    "    for i, column in enumerate(numeric_columns.columns):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        sns.set(style=\"ticks\")\n",
    "        sns.histplot(data=numeric_columns[column], bins=30, kde=True, ax=axes[row, col])\n",
    "        axes[row, col].set_title(f\"Histogram of {column}\")\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# review one at a time\n",
    "sns.histplot(team_week_stats['pass_touchdowns'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# review all numeric columns\n",
    "\n",
    "# columns we've already decided to keep or drop\n",
    "numeric_columns_to_drop={'start_team_wp', 'wopr', 'start_team_wp', 'half_team_wp', 'start_opponent_wp', 'half_opponent_wp',  'racr', 'avg_rushing_epa', 'avg_receiving_epa', 'target_share', 'passing_epa', 'avg_pacr', 'sack', 'count', 'interception', 'air_yards_share'}\n",
    "numeric_columns_to_hide={'season','week', 'opposing_score', 'team_score', 'spread', 'interceptions'}\n",
    "\n",
    "# all numeric columns and their values\n",
    "numeric_columns = team_week_stats.select_dtypes(include='number').drop(columns=list(numeric_columns_to_drop.union(numeric_columns_to_hide)) ) ## review whats left over\n",
    "\n",
    "# columns with less than '20' unique values are really categories - they don't really have a distribution worth looking at per-se\n",
    "categorical_columns = set()\n",
    "for column in numeric_columns.columns:\n",
    "    n = len(numeric_columns[column].value_counts())\n",
    "    if n < 20:\n",
    "        categorical_columns.add(column)\n",
    "\n",
    "# drop categorical columns from our numeric dataset\n",
    "numeric_columns = numeric_columns.drop(columns=list(categorical_columns))\n",
    "\n",
    "# review the distribution of the remaining columns\n",
    "hist_charts(numeric_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">drop the columns we don't need</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "team_week_stats.drop(columns=list(numeric_columns_to_drop), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">make sure our potential labels for the upcoming dimension analysis is complete</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert 0 == team_week_stats.spread.isna().sum()\n",
    "assert 0 == team_week_stats.team_score.isna().sum()\n",
    "assert 0 == team_week_stats.opposing_score.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color=\"#9370DB\">store to database</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "if COMMIT_TO_DATABASE:\n",
    "    db.load_table(merged, table_name=\"team_weekly_stats\", schema=SCHEMA, handle_exists=\"replace\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
